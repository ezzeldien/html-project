<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">
    <meta name="description" content="about artificial intelligence and its advantages and disadvantages">  
        <title>"AI development"</title>
        <link rel="stylesheet" href="C:\Users\az\untitled-1.html">
    </head>  
        <body>
         <center><h1>AI development</h1></center>
            <h1><name>Links:-</name></h1>
        
            <ul>
                <li><h1> <a href="C:\Users\az\untitled-1.html">*AI main web page</a></h1></li>
                <li><h1> <a href="C:\Users\az\introduction.html">*Inrtoduction</a></h1></li>
                <li><h1><a href="C:\Users\az\AI development.html">*AI development</a></h1></li>
                <li><h1><a href="C:\Users\az\AI states.html">*AI states</a></h1></li>
                <li><h1><a href="C:\Users\az\AI uses.html">*AI uses</a></h1></li>
            </ul>
         <p>So far, AI4SG has been developed ad hoc, by analysing specific areas of application,
            such as famine relief or disaster management. This approach can indicate the presence of a phenomenon,
        <br> 
            but it cannot explain what exactly makes AI socially good nor can it indicate how AI4SG solutions could and should be designed and deployed to harness the full potential of the technology.
            These two shortcomings raise at least three main risks: unanticipated failures, missed opportunities and unwarranted interventions.</p>
        <br>
        <p>We consider unanticipated failures first. Like any other technology, 
                AI solutions are shaped by human values. Such values, if not carefully selected and fostered, may lead to ‘good AI gone awry’ scenarios.
                AI may ‘do more harm than good’, amplifying rather than mitigating societal ills, for example, by widening rather than narrowing existing inequities,
                or by exacerbating environmental problems. AI may simply fail to serve the social good. 
                For example, consider the failure of IBM’s oncology-support software, which attempted to use machine learning to identify cancerous tumours.
                The system was trained using synthetic data and US medical protocols, which are not applicable worldwide. As a result, it struggled to interpret ambiguous, nuanced or otherwise ‘messy’ patient health records14, and provided misdiagnoses and erroneous treatment suggestions. This led medical practitioners and hospital to reject the Watson system</p>
         <center><img src="https://assets.entrepreneur.com/content/3x2/2000/20200316170356-GettyImages-1145585734.jpeg" width="750" height="500"></center>
        </body>
</html>